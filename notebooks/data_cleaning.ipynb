{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b042c937",
   "metadata": {},
   "source": [
    "# Uber Dataset - Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469eb326",
   "metadata": {},
   "source": [
    "## 1. Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5326afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../data/ncr_ride_bookings_raw.csv')\n",
    "\n",
    "# Initial inspection\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894069b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a48436b",
   "metadata": {},
   "source": [
    "## 2. Handle data type issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b33fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes from string columns\n",
    "str_cols = df.select_dtypes(include=['object']).columns # Identify string columns\n",
    "for col in str_cols:\n",
    "    df[col] = df[col].astype(str).str.replace('\"', '', regex=False) # Remove quotes\n",
    "\n",
    "# Convert date/time columns to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Create a combined datetime column\n",
    "df['Booking_Datetime'] = pd.to_datetime(\n",
    "    df['Date'].astype(str) + ' ' + df['Time'].astype(str)\n",
    ")\n",
    "\n",
    "# Extract additional temporal features\n",
    "df['Year'] = df['Booking_Datetime'].dt.year\n",
    "df['Month'] = df['Booking_Datetime'].dt.month\n",
    "df['Month_Name'] = df['Booking_Datetime'].dt.month_name()\n",
    "df['Day'] = df['Booking_Datetime'].dt.day\n",
    "df['Day_of_Week'] = df['Booking_Datetime'].dt.day_name()\n",
    "df['Hour'] = df['Booking_Datetime'].dt.hour\n",
    "\n",
    "# Create buckets for analysis\n",
    "def categorize_time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "    \n",
    "df['Time_of_Day'] = df['Hour'].apply(categorize_time_of_day)\n",
    "\n",
    "# Convert categorical columns to category dtype, optimizing memory usage\n",
    "categorical_cols = [\n",
    "    'Booking Status', \n",
    "    'Vehicle Type',\n",
    "    'Pickup Location',\n",
    "    'Drop Location',\n",
    "    'Reason for cancelling by Customer',\n",
    "    'Driver Cancellation Reason',\n",
    "    'Incomplete Rides Reason',\n",
    "    'Payment Method',\n",
    "    'Month_Name',\n",
    "    'Day_of_Week',\n",
    "    'Time_of_Day'\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Convert numerical columns to appropriate dtypes, handling errors\n",
    "numerical_cols = ['Avg VTAT', 'Avg CTAT', 'Booking Value', 'Ride Distance', \n",
    "                'Driver Ratings', 'Customer Rating', 'Cancelled Rides by Customer',\n",
    "                'Cancelled Rides by Driver', 'Incomplete Rides']\n",
    "for col in numerical_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce') # Convert to numeric, coercing errors to NaN\n",
    "\n",
    "# Final inspection\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9fc46d",
   "metadata": {},
   "source": [
    "## 3. Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3119fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flag for incomplete data\n",
    "df['Has_Missing_Values'] = df.isnull().any(axis=1)\n",
    "\n",
    "# Document missing value patterns\n",
    "missing_value_summary = df.isnull().sum()\n",
    "print(missing_value_summary[missing_value_summary > 0])\n",
    "\n",
    "# Handle nulls based on booking status logic\n",
    "# - No Driver Found: Expected to have nulls in VTAT, CTAT, ratings, etc.\n",
    "# - Cancelled Rides: May have nulls in completion metrics\n",
    "# - Incomplete Rides: Should have nulls in completion metrics; reason should be filled\n",
    "# - Completed Rides: Should have minimal nulls; investigate any present\n",
    "\n",
    "# Create completeness flags\n",
    "df['Is_Completed'] = df['Booking Status'] == 'Completed'\n",
    "df['Is_Cancelled'] = df['Booking Status'].str.contains('Cancelled', case=False, na=False)\n",
    "df['Is_Incomplete'] = df['Booking Status'] == 'Incomplete'\n",
    "df['No_Driver_Found'] = df['Booking Status'] == 'No Driver Found'\n",
    "\n",
    "# Fill missing reasons for incomplete rides and cancellations\n",
    "reason_cols = [\n",
    "    'Incomplete Rides Reason',\n",
    "    'Driver Cancellation Reason',\n",
    "    'Reason for cancelling by Customer'\n",
    "]\n",
    "\n",
    "# Ensure 'Reason Not Provided' category exists\n",
    "for col in reason_cols:\n",
    "    if isinstance(df[col].dtype, pd.CategoricalDtype):\n",
    "        if 'Reason Not Provided' not in df[col].cat.categories:\n",
    "            df[col] = df[col].cat.add_categories(['Reason Not Provided'])\n",
    "\n",
    "\n",
    "# Fill missing incomplete ride reasons\n",
    "df.loc[df['Is_Incomplete'] & df['Incomplete Rides Reason'].isnull(),\n",
    "       'Incomplete Rides Reason'] = 'Reason Not Provided'\n",
    "\n",
    "df.loc[df['Is_Cancelled'] & df['Driver Cancellation Reason'].isnull(),\n",
    "       'Driver Cancellation Reason'] = 'Reason Not Provided'\n",
    "\n",
    "df.loc[df['Is_Cancelled'] & df['Reason for cancelling by Customer'].isnull(),\n",
    "       'Reason for cancelling by Customer'] = 'Reason Not Provided'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e48e3",
   "metadata": {},
   "source": [
    "## 4. Create Calculated Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue Metrics\n",
    "df['Revenue_per_KM'] = df['Booking Value'] / df['Ride Distance']\n",
    "df['Revenue_per_KM'] = df['Revenue_per_KM'].replace([np.inf, -np.inf], np.nan)  # Handle division by zero\n",
    "\n",
    "# Efficiency metrics\n",
    "df['Total_TAT'] = df['Avg VTAT'] + df['Avg CTAT']\n",
    "\n",
    "# Rating difference (customer satisfaction vs driver performance)\n",
    "df['Rating_Difference'] = df['Customer Rating'] - df['Driver Ratings']\n",
    "\n",
    "# Distance categories\n",
    "def categorize_distance(distance):\n",
    "    if pd.isnull(distance):\n",
    "        return 'Unknown'\n",
    "    elif distance < 5:\n",
    "        return 'Short'\n",
    "    elif 5 <= distance < 15:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Long'\n",
    "    \n",
    "df['Distance_Category'] = df['Ride Distance'].apply(categorize_distance)\n",
    "\n",
    "# Value categories\n",
    "def categorize_value(value):\n",
    "    if pd.isnull(value):\n",
    "        return 'Unknown'\n",
    "    elif value < 100:\n",
    "        return 'Low'\n",
    "    elif 100 <= value < 500:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "    \n",
    "df['Value_Category'] = df['Booking Value'].apply(categorize_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be75c57",
   "metadata": {},
   "source": [
    "## 5. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f84367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate booking IDs\n",
    "duplicate_booking_id = df.duplicated(subset=['Booking ID'], keep=False)\n",
    "print(f\"Number of duplicate booking IDs found: {duplicate_booking_id.sum()}\")\n",
    "# If duplicates exist, drop or investigate further\n",
    "df = df.drop_duplicates(subset=['Booking ID'], keep='first')\n",
    "\n",
    "# Check for logical inconsistencies (E.g., Completed rides with null VTAT/CTAT)\n",
    "inconsistent_completed_rides = df[\n",
    "    (df['Is_Completed']) & \n",
    "    (df['Avg VTAT'].isnull() | df['Avg CTAT'].isnull())\n",
    "]\n",
    "print(f\"Number of inconsistent completed rides found: {len(inconsistent_completed_rides)}\")\n",
    "\n",
    "# Validate calculated fields\n",
    "invalid_revenue_per_km = df[\n",
    "    (df['Revenue_per_KM'] < 0) |\n",
    "    (df['Revenue_per_KM'].isnull() & df['Booking Value'].notnull() & df['Ride Distance'].notnull())\n",
    "]\n",
    "print(f\"Number of invalid Revenue_per_KM entries found: {len(invalid_revenue_per_km)}\")\n",
    "\n",
    "# Validate ratings are within expected range (0-5) \n",
    "# Driver Ratings\n",
    "invalid_driver_ratings = df[\n",
    "    (df['Driver Ratings'] < 0) | (df['Driver Ratings'] > 5)\n",
    "]\n",
    "print(f\"Number of invalid Driver Ratings entries found: {len(invalid_driver_ratings)}\")\n",
    "# Customer Ratings\n",
    "invalid_customer_ratings = df[\n",
    "    (df['Customer Rating'] < 0) | (df['Customer Rating'] > 5)\n",
    "]\n",
    "print(f\"Number of invalid Customer Ratings entries found: {len(invalid_customer_ratings)}\")\n",
    "\n",
    "# Check for negative values where they shouldn't be\n",
    "negative_checks = ['Booking Value', 'Ride Distance', 'Avg VTAT', 'Avg CTAT']\n",
    "for col in negative_checks:\n",
    "    negatives = df[df[col] < 0]\n",
    "    print(f\"Number of negative entries in {col}: {len(negatives)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea298968",
   "metadata": {},
   "source": [
    "## 6. Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef1062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/uber_dataset_cleaned.csv', index=False)\n",
    "\n",
    "# Create a version for PostgreSQL (with proper formatting)\n",
    "df.to_csv('../data/uber_dataset_postgresql.csv', index=False, date_format='%Y-%m-%d')\n",
    "\n",
    "print(\"Cleaned data exported successfully.\")\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"Cleaned rows: {len(df)}\")\n",
    "print(f\"Columns added: {len(df.columns) - len(pd.read_csv('../data/ncr_ride_bookings_raw.csv').columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (biodiversity)",
   "language": "python",
   "name": "biodiversity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
